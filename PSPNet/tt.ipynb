{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5] \n",
      "\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      " 0  1  2\n",
      " 3  4  5\n",
      "[torch.LongTensor of size 2x3]\n",
      "\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np_data = np.arange(6).reshape((2, 3))\n",
    "torch_data = torch.from_numpy(np_data)\n",
    "tensor2array = torch_data.numpy()\n",
    "\n",
    "print np.arange(6),\"\\n\"\n",
    "print np_data\n",
    "print torch_data\n",
    "print tensor2array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 4]\n",
      "\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 4\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "0.75\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "data = [-1, -2, 2, 4]\n",
    "tensor = torch.FloatTensor(data)\n",
    "\n",
    "print np.abs(data)\n",
    "print torch.abs(tensor)\n",
    "print np.mean(data)\n",
    "print torch.mean(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "tensor = torch.FloatTensor([[1,2],[3,4]])\n",
    "variable = Variable(tensor, requires_grad=True)\n",
    "print(tensor)\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "Variable containing:\n",
      " 7.5000\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      "  5.5000  11.0000\n",
      " 16.5000  22.0000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_out = torch.mean(tensor*tensor)       # x^2\n",
    "v_out = torch.mean(variable*variable)   # x^2\n",
    "print(t_out)\n",
    "print(v_out)\n",
    "v_out.backward()\n",
    "print(variable.grad)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "\n",
      " 1  2\n",
      " 3  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "print(variable)     \n",
    "print(variable.data)   \n",
    "print(variable.data.numpy())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = torch.linspace(-5, 5, 200)\n",
    "x = Variable(x)\n",
    "x_np = x.data.numpy()\n",
    "\n",
    "y_relu = F.relu(x).data.numpy()\n",
    "y_sigmoid = F.sigmoid(x).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(121)\n",
    "plt.plot(x_np, y_relu, c='red', label='relu')\n",
    "plt.ylim((-1, 5))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x_np, y_sigmoid, c='blue', label='sigmoid')\n",
    "plt.ylim((-0.2, 1.3))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 5           # train the training data n times\n",
    "BATCH_SIZE = 100\n",
    "LR = 0.01           # learning rate\n",
    "DOWNLOAD_MNIST = False\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    DOWNLOAD_MNIST = True\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                     # this is training data\n",
    "    # Converts a PIL.Image or numpy.ndarray to\n",
    "    # torch.FloatTensor of shape (C x H x W) \n",
    "    # and normalize in the range [0.0, 1.0]\n",
    "    transform=torchvision.transforms.ToTensor(),    \n",
    "    download=DOWNLOAD_MNIST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADgdJREFUeJzt3X9sXfV5x/HPs9D8QRoIXjUTpWFpIhQUIuZOJkwoGkXM5YeCggGhWkLKRBT3j1ii0hQNZX8MNAVFg2RqBKrsqqHJ1KWZBCghqpp0CZBOTBEmhF9mKQylqi2TFAWTH/zIHD/74x53Lvh+r3Pvufdc+3m/JMv3nuecex4d5ZPz8/pr7i4A8fxJ0Q0AKAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1GWNXJmZ8TghUGfublOZr6Y9v5ndYWbHzex9M3ukls8C0FhW7bP9ZjZL0m8kdUgalPSqpC53H0gsw54fqLNG7PlXSHrf3T9w9wuSfi5pdQ2fB6CBagn/Akm/m/B+MJv2R8ys28z6zay/hnUByFndL/i5e5+kPonDfqCZ1LLnH5K0cML7b2bTAEwDtYT/VUnXmtm3zGy2pO9J2ptPWwDqrerDfncfNbMeSfslzZK03d3fya0zAHVV9a2+qlbGOT9Qdw15yAfA9EX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFUP0S1JZnZC0llJFyWNunt7Hk0hP7NmzUrWr7zyyrquv6enp2zt8ssvTy67dOnSZH39+vXJ+pNPPlm21tXVlVz2888/T9Y3b96crD/22GPJejOoKfyZW939oxw+B0ADcdgPBFVr+F3SATN7zcy682gIQGPUeti/0t2HzOzPJP3KzP7b3Q9PnCH7T4H/GIAmU9Oe392Hst+nJD0vacUk8/S5ezsXA4HmUnX4zWyOmc0dfy3pu5LezqsxAPVVy2F/q6TnzWz8c/7N3X+ZS1cA6q7q8Lv7B5L+IsdeZqxrrrkmWZ89e3ayfvPNNyfrK1euLFubN29ectn77rsvWS/S4OBgsr5t27ZkvbOzs2zt7NmzyWXfeOONZP3ll19O1qcDbvUBQRF+ICjCDwRF+IGgCD8QFOEHgjJ3b9zKzBq3sgZqa2tL1g8dOpSs1/trtc1qbGwsWX/ooYeS9XPnzlW97uHh4WT9448/TtaPHz9e9brrzd1tKvOx5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoLjPn4OWlpZk/ciRI8n64sWL82wnV5V6HxkZSdZvvfXWsrULFy4kl436/EOtuM8PIInwA0ERfiAowg8ERfiBoAg/EBThB4LKY5Te8E6fPp2sb9iwIVlftWpVsv76668n65X+hHXKsWPHkvWOjo5k/fz588n69ddfX7b28MMPJ5dFfbHnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgKn6f38y2S1ol6ZS7L8+mtUjaLWmRpBOSHnD39B8618z9Pn+trrjiimS90nDSvb29ZWtr165NLvvggw8m67t27UrW0Xzy/D7/TyXd8aVpj0g66O7XSjqYvQcwjVQMv7sflvTlR9hWS9qRvd4h6Z6c+wJQZ9We87e6+/h4Rx9Kas2pHwANUvOz/e7uqXN5M+uW1F3regDkq9o9/0kzmy9J2e9T5WZ09z53b3f39irXBaAOqg3/XklrstdrJO3Jpx0AjVIx/Ga2S9J/SVpqZoNmtlbSZkkdZvaepL/J3gOYRiqe87t7V5nSbTn3EtaZM2dqWv6TTz6petl169Yl67t3707Wx8bGql43isUTfkBQhB8IivADQRF+ICjCDwRF+IGgGKJ7BpgzZ07Z2gsvvJBc9pZbbknW77zzzmT9wIEDyToajyG6ASQRfiAowg8ERfiBoAg/EBThB4Ii/EBQ3Oef4ZYsWZKsHz16NFkfGRlJ1l988cVkvb+/v2zt6aefTi7byH+bMwn3+QEkEX4gKMIPBEX4gaAIPxAU4QeCIvxAUNznD66zszNZf+aZZ5L1uXPnVr3ujRs3Jus7d+5M1oeHh5P1qLjPDyCJ8ANBEX4gKMIPBEX4gaAIPxAU4QeCqnif38y2S1ol6ZS7L8+mPSppnaTfZ7NtdPdfVFwZ9/mnneXLlyfrW7duTdZvu636kdx7e3uT9U2bNiXrQ0NDVa97OsvzPv9PJd0xyfR/cfe27Kdi8AE0l4rhd/fDkk43oBcADVTLOX+Pmb1pZtvN7KrcOgLQENWG/0eSlkhqkzQsaUu5Gc2s28z6zaz8H3MD0HBVhd/dT7r7RXcfk/RjSSsS8/a5e7u7t1fbJID8VRV+M5s/4W2npLfzaQdAo1xWaQYz2yXpO5K+YWaDkv5R0nfMrE2SSzoh6ft17BFAHfB9ftRk3rx5yfrdd99dtlbpbwWYpW9XHzp0KFnv6OhI1mcqvs8PIInwA0ERfiAowg8ERfiBoAg/EBS3+lCYL774Ilm/7LL0Yyijo6PJ+u2331629tJLLyWXnc641QcgifADQRF+ICjCDwRF+IGgCD8QFOEHgqr4fX7EdsMNNyTr999/f7J+4403lq1Vuo9fycDAQLJ++PDhmj5/pmPPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcZ9/hlu6dGmy3tPTk6zfe++9yfrVV199yT1N1cWLF5P14eHhZH1sbCzPdmYc9vxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTF+/xmtlDSTkmtklxSn7v/0MxaJO2WtEjSCUkPuPvH9Ws1rkr30ru6usrWKt3HX7RoUTUt5aK/vz9Z37RpU7K+d+/ePNsJZyp7/lFJf+fuyyT9laT1ZrZM0iOSDrr7tZIOZu8BTBMVw+/uw+5+NHt9VtK7khZIWi1pRzbbDkn31KtJAPm7pHN+M1sk6duSjkhqdffx5ys/VOm0AMA0MeVn+83s65KelfQDdz9j9v/Dgbm7lxuHz8y6JXXX2iiAfE1pz29mX1Mp+D9z9+eyySfNbH5Wny/p1GTLunufu7e7e3seDQPIR8XwW2kX/xNJ77r71gmlvZLWZK/XSNqTf3sA6qXiEN1mtlLSryW9JWn8O5IbVTrv/3dJ10j6rUq3+k5X+KyQQ3S3tqYvhyxbtixZf+qpp5L166677pJ7ysuRI0eS9SeeeKJsbc+e9P6Cr+RWZ6pDdFc853f3/5RU7sNuu5SmADQPnvADgiL8QFCEHwiK8ANBEX4gKMIPBMWf7p6ilpaWsrXe3t7ksm1tbcn64sWLq+opD6+88kqyvmXLlmR9//79yfpnn312yT2hMdjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQYe7z33TTTcn6hg0bkvUVK1aUrS1YsKCqnvLy6aeflq1t27Ytuezjjz+erJ8/f76qntD82PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBh7vN3dnbWVK/FwMBAsr5v375kfXR0NFlPfed+ZGQkuSziYs8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZu6dnMFsoaaekVkkuqc/df2hmj0paJ+n32awb3f0XFT4rvTIANXN3m8p8Uwn/fEnz3f2omc2V9JqkeyQ9IOmcuz851aYIP1B/Uw1/xSf83H1Y0nD2+qyZvSup2D9dA6Bml3TOb2aLJH1b0pFsUo+ZvWlm283sqjLLdJtZv5n119QpgFxVPOz/w4xmX5f0sqRN7v6cmbVK+kil6wD/pNKpwUMVPoPDfqDOcjvnlyQz+5qkfZL2u/vWSeqLJO1z9+UVPofwA3U21fBXPOw3M5P0E0nvTgx+diFwXKekty+1SQDFmcrV/pWSfi3pLUlj2eSNkroktal02H9C0vezi4Opz2LPD9RZrof9eSH8QP3ldtgPYGYi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBNXoIbo/kvTbCe+/kU1rRs3aW7P2JdFbtfLs7c+nOmNDv8//lZWb9bt7e2ENJDRrb83al0Rv1SqqNw77gaAIPxBU0eHvK3j9Kc3aW7P2JdFbtQrprdBzfgDFKXrPD6AghYTfzO4ws+Nm9r6ZPVJED+WY2Qkze8vMjhU9xFg2DNopM3t7wrQWM/uVmb2X/Z50mLSCenvUzIaybXfMzO4qqLeFZvaimQ2Y2Ttm9nA2vdBtl+irkO3W8MN+M5sl6TeSOiQNSnpVUpe7DzS0kTLM7ISkdncv/J6wmf21pHOSdo6PhmRm/yzptLtvzv7jvMrd/75JentUlzhyc516Kzey9N+qwG2X54jXeShiz79C0vvu/oG7X5D0c0mrC+ij6bn7YUmnvzR5taQd2esdKv3jabgyvTUFdx9296PZ67OSxkeWLnTbJfoqRBHhXyDpdxPeD6q5hvx2SQfM7DUz6y66mUm0ThgZ6UNJrUU2M4mKIzc30pdGlm6abVfNiNd544LfV61097+UdKek9dnhbVPy0jlbM92u+ZGkJSoN4zYsaUuRzWQjSz8r6QfufmZirchtN0lfhWy3IsI/JGnhhPffzKY1BXcfyn6fkvS8SqcpzeTk+CCp2e9TBffzB+5+0t0vuvuYpB+rwG2XjSz9rKSfuftz2eTCt91kfRW13YoI/6uSrjWzb5nZbEnfk7S3gD6+wszmZBdiZGZzJH1XzTf68F5Ja7LXayTtKbCXP9IsIzeXG1laBW+7phvx2t0b/iPpLpWu+P+PpH8ooocyfS2W9Eb2807RvUnapdJh4P+qdG1kraQ/lXRQ0nuS/kNSSxP19q8qjeb8pkpBm19QbytVOqR/U9Kx7Oeuorddoq9CthtP+AFBccEPCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ/weCC5r/92q6mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())                 \n",
    "print(train_data.train_labels.size())              \n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([10000, 1, 28, 28]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# the image batch shape will be (batch_size, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# pick 2000 samples to speed up testing\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "# shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)/255.   \n",
    "test_y = test_data.test_labels\n",
    "print test_x.shape, test_y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's length: 60000\n",
      "train_loader's length: 600\n"
     ]
    }
   ],
   "source": [
    "#batch_size=16\n",
    "print \"train_data's length:\",len(train_data)\n",
    "print \"train_loader's length:\",len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input channels\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # output width=(widthâˆ’kernel_size+2pad)/stride +1\n",
    "            ),                              # output width=(28-5+2*2)/1 +1=28\n",
    "                                            # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)      \n",
    "        output = self.out(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)  # net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  train loss:2.3013  test accuracy:0.097\n",
      "Epoch: 0  train loss:0.1047  test accuracy:0.972\n",
      "Epoch: 0  train loss:0.0377  test accuracy:0.965\n",
      "Epoch: 0  train loss:0.0900  test accuracy:0.977\n",
      "Epoch: 0  train loss:0.1658  test accuracy:0.977\n",
      "Epoch: 0  train loss:0.1477  test accuracy:0.981\n",
      "Epoch: 1  train loss:0.0304  test accuracy:0.982\n",
      "Epoch: 1  train loss:0.0190  test accuracy:0.984\n",
      "Epoch: 1  train loss:0.0785  test accuracy:0.985\n",
      "Epoch: 1  train loss:0.0303  test accuracy:0.984\n",
      "Epoch: 1  train loss:0.0574  test accuracy:0.981\n",
      "Epoch: 1  train loss:0.0167  test accuracy:0.986\n",
      "Epoch: 2  train loss:0.0052  test accuracy:0.982\n",
      "Epoch: 2  train loss:0.0471  test accuracy:0.986\n",
      "Epoch: 2  train loss:0.1207  test accuracy:0.980\n",
      "Epoch: 2  train loss:0.2241  test accuracy:0.981\n",
      "Epoch: 2  train loss:0.0122  test accuracy:0.984\n",
      "Epoch: 2  train loss:0.1199  test accuracy:0.980\n",
      "Epoch: 3  train loss:0.0918  test accuracy:0.980\n",
      "Epoch: 3  train loss:0.0094  test accuracy:0.987\n",
      "Epoch: 3  train loss:0.0148  test accuracy:0.986\n",
      "Epoch: 3  train loss:0.0191  test accuracy:0.987\n",
      "Epoch: 3  train loss:0.0583  test accuracy:0.980\n",
      "Epoch: 3  train loss:0.0652  test accuracy:0.981\n",
      "Epoch: 4  train loss:0.1145  test accuracy:0.986\n",
      "Epoch: 4  train loss:0.0247  test accuracy:0.986\n",
      "Epoch: 4  train loss:0.0463  test accuracy:0.987\n",
      "Epoch: 4  train loss:0.1236  test accuracy:0.986\n",
      "Epoch: 4  train loss:0.0040  test accuracy:0.987\n",
      "Epoch: 4  train loss:0.3553  test accuracy:0.982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "208.28215098381042"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from torch.autograd import Variable\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "# training\n",
    "aa=time.time()\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        b_x=Variable(b_x)\n",
    "        b_y=Variable(b_y)\n",
    "        output = cnn(b_x)               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            test_output = cnn(Variable(test_x))\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            acc= (pred_y ==Variable(test_y).data.numpy()).astype(int).sum()/float(test_y.size(0))\n",
    "            print 'Epoch:',epoch,' train loss:%.4f' %loss.data.numpy(),' test accuracy:%.3f' %acc\n",
    "time.time()-aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10]) \n",
      "\n",
      "Variable containing:\n",
      " 16.0398\n",
      " 18.1984\n",
      "  8.2497\n",
      " 11.9835\n",
      " 16.7772\n",
      "  9.3603\n",
      "  8.3707\n",
      " 13.5447\n",
      " 12.6686\n",
      " 10.0674\n",
      " 17.9452\n",
      " 16.1196\n",
      " 14.8201\n",
      " 17.8345\n",
      " 11.0892\n",
      " 14.6689\n",
      " 15.8796\n",
      " 19.5271\n",
      "  1.6231\n",
      " 19.6039\n",
      "  6.7448\n",
      " 15.4297\n",
      " 18.0711\n",
      " 16.1308\n",
      " 13.1724\n",
      " 12.4532\n",
      " 17.7302\n",
      " 24.8392\n",
      " 11.5933\n",
      "  7.4988\n",
      "[torch.FloatTensor of size 30]\n",
      "\n",
      "Variable containing:\n",
      " 7\n",
      " 2\n",
      " 1\n",
      " 0\n",
      " 4\n",
      " 1\n",
      " 4\n",
      " 9\n",
      " 5\n",
      " 9\n",
      " 0\n",
      " 6\n",
      " 9\n",
      " 0\n",
      " 1\n",
      " 5\n",
      " 9\n",
      " 7\n",
      " 3\n",
      " 4\n",
      " 9\n",
      " 6\n",
      " 6\n",
      " 5\n",
      " 4\n",
      " 0\n",
      " 7\n",
      " 4\n",
      " 0\n",
      " 1\n",
      "[torch.LongTensor of size 30]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test=Variable(test_x[:30])\n",
    "test_output = cnn(test)\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "\n",
    "print test_output.shape,\"\\n\"\n",
    "print torch.max(test_output, 1)[0]\n",
    "print torch.max(test_output, 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1] real number\n"
     ]
    }
   ],
   "source": [
    "print pred_y, 'prediction number'\n",
    "print test_y[:30].numpy(), 'real number'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  train loss:2.3063  test accuracy:0.159\n",
      "Epoch: 0  train loss:0.1355  test accuracy:0.949\n",
      "Epoch: 0  train loss:0.0656  test accuracy:0.969\n",
      "Epoch: 0  train loss:0.1027  test accuracy:0.969\n",
      "Epoch: 0  train loss:0.0703  test accuracy:0.978\n",
      "Epoch: 0  train loss:0.1169  test accuracy:0.976\n",
      "Epoch: 1  train loss:0.0431  test accuracy:0.981\n",
      "Epoch: 1  train loss:0.0536  test accuracy:0.982\n",
      "Epoch: 1  train loss:0.1091  test accuracy:0.980\n",
      "Epoch: 1  train loss:0.0167  test accuracy:0.982\n",
      "Epoch: 1  train loss:0.0482  test accuracy:0.980\n",
      "Epoch: 1  train loss:0.1124  test accuracy:0.983\n",
      "Epoch: 2  train loss:0.0253  test accuracy:0.980\n",
      "Epoch: 2  train loss:0.0202  test accuracy:0.983\n",
      "Epoch: 2  train loss:0.0101  test accuracy:0.982\n",
      "Epoch: 2  train loss:0.0787  test accuracy:0.981\n",
      "Epoch: 2  train loss:0.0762  test accuracy:0.983\n",
      "Epoch: 2  train loss:0.0461  test accuracy:0.981\n",
      "Epoch: 3  train loss:0.0181  test accuracy:0.985\n",
      "Epoch: 3  train loss:0.0929  test accuracy:0.984\n",
      "Epoch: 3  train loss:0.0335  test accuracy:0.983\n",
      "Epoch: 3  train loss:0.1149  test accuracy:0.983\n",
      "Epoch: 3  train loss:0.0670  test accuracy:0.981\n",
      "Epoch: 3  train loss:0.0765  test accuracy:0.984\n",
      "Epoch: 4  train loss:0.0121  test accuracy:0.976\n",
      "Epoch: 4  train loss:0.0114  test accuracy:0.981\n",
      "Epoch: 4  train loss:0.0455  test accuracy:0.980\n",
      "Epoch: 4  train loss:0.0390  test accuracy:0.984\n",
      "Epoch: 4  train loss:0.0955  test accuracy:0.983\n",
      "Epoch: 4  train loss:0.0445  test accuracy:0.985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.878260135650635"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from torch.autograd import Variable\n",
    "cnn = CNN().cuda()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "# training\n",
    "aa=time.time()\n",
    "test_x=Variable(test_x).cuda()\n",
    "test_y=Variable(test_y).cuda()\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        b_x=Variable(b_x).cuda()\n",
    "        b_y=Variable(b_y).cuda()\n",
    "        output = cnn(b_x)               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            test_output = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
    "            acc= (pred_y ==test_y.data.cpu().numpy()).astype(int).sum()/float(test_y.size(0))\n",
    "            print 'Epoch:',epoch,' train loss:%.4f' %loss.data.cpu().numpy(),' test accuracy:%.3f' %acc\n",
    "time.time()-aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "   0   1\n",
      "   2   3\n",
      "\n",
      "(1 ,.,.) = \n",
      "   4   5\n",
      "   6   7\n",
      "\n",
      "(2 ,.,.) = \n",
      "   8   9\n",
      "  10  11\n",
      "\n",
      "(3 ,.,.) = \n",
      "  12  13\n",
      "  14  15\n",
      "[torch.FloatTensor of size 4x2x2]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  16  17\n",
      "  18  19\n",
      "\n",
      "(1 ,.,.) = \n",
      "  20  21\n",
      "  22  23\n",
      "\n",
      "(2 ,.,.) = \n",
      "  24  25\n",
      "  26  27\n",
      "\n",
      "(3 ,.,.) = \n",
      "  28  29\n",
      "  30  31\n",
      "[torch.FloatTensor of size 4x2x2]\n",
      "\n",
      "\n",
      "(0 ,.,.) = \n",
      "  32  33\n",
      "  34  35\n",
      "\n",
      "(1 ,.,.) = \n",
      "  36  37\n",
      "  38  39\n",
      "\n",
      "(2 ,.,.) = \n",
      "  40  41\n",
      "  42  43\n",
      "\n",
      "(3 ,.,.) = \n",
      "  44  45\n",
      "  46  47\n",
      "[torch.FloatTensor of size 4x2x2]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -1.2683 -1.1958\n",
      " -1.1233 -1.0508\n",
      "\n",
      "(1 ,.,.) = \n",
      " -1.1149 -1.0512\n",
      " -0.9875 -0.9238\n",
      "\n",
      "(2 ,.,.) = \n",
      " -0.0342 -0.0323\n",
      " -0.0303 -0.0284\n",
      "\n",
      "(3 ,.,.) = \n",
      " -1.0084 -0.9507\n",
      " -0.8931 -0.8355\n",
      "[torch.FloatTensor of size 4x2x2]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.1087 -0.0362\n",
      "  0.0362  0.1087\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.0956 -0.0319\n",
      "  0.0319  0.0956\n",
      "\n",
      "(2 ,.,.) = \n",
      " -0.0029 -0.0010\n",
      "  0.0010  0.0029\n",
      "\n",
      "(3 ,.,.) = \n",
      " -0.0864 -0.0288\n",
      "  0.0288  0.0864\n",
      "[torch.FloatTensor of size 4x2x2]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1.0508  1.1233\n",
      "  1.1958  1.2683\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.9238  0.9875\n",
      "  1.0512  1.1149\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.0284  0.0303\n",
      "  0.0323  0.0342\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.8355  0.8931\n",
      "  0.9507  1.0084\n",
      "[torch.FloatTensor of size 4x2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in x:\n",
    "    print i\n",
    "for i in output:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
